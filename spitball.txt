# GNU nano 4.8                                                             spitball.txt                                                                       
# Feb 23 2022
#
#       I have the words.txt file as well as a working letterCount program. What I'm doing now is just typing out what I've done to see if an idea will pop
#       into my head. I'm also supposed to have students come for help on a CS I lab but no one's here so I'm doing this.
#       Right now I'm ignoring the Segmentation Fault error in wordEff because it's a storage problem idk how to fix since I'm proficient with memory
#       allocation. So instead of doing that, I'm trying to think of what would actually define the best word. In my opinion, it would be related to graph
#       theory, involving relationships between words based on what letters they have and where they appear from. In my head, I'm picturing that all words
#       fall into at least one type of category. I picure it like playing Guess Who, where on your first guess you want to at least split your remaining
#       options in half. Characters have different assortments of skin color, gender, hair, eyes, and accessories. Due to characters having some type of
#       feature or no feature in these categories, it makes it easier to organize them into groups. A lot of this is just trying to make sense of what's
#       in my head, but the graph theory/Guess Who type strategy I believe is my best option.
#       There would be 15 relations with X being doesn't contain, O being wrong spot, and $ being correct:
#
#       XXXXX
#       XXXXO
#       XXXOO
#       XXOOO
#       XOOOO
#       OOOOO
#       XXXX$
#       XXX$$
#       XX$$$
#       X$$$$
#       $$$$$
#       OOOO$
#       OOO$$
#       OO$$$
#       O$$$$
#
#       Using these different relationships, I believe we can make either a graph or matrix that can find the best possible word, similar to Sudoku.
#       I'm just starting to learn graph theory in Discrete II right now but I think watching more videos and doing some practice through a Sudoku
#       solver, I think I could come up with something for this.
#
#       Maybe an epiphany, but knowing there are 15 possible relations, the best word would split all words as close to evenly among these 15 groups.
#       In the best case (12972/15 ceiling) would leave us with 865 possible solutions. I guess I could make an int array[15] to contain how many times
#       each relation appears and then scoring each word based on the Standard Deviation betweem members of each relation. Guess I don't need Sudoku,
#       still gonna make a solver eventually.
# 
#       My only concern is how much storage this is going to take. I need a [12972*5] 2d char array for each word from words.txt, a [26] char array for the
#       alphabet, and [15] int array for all 12972 words and potentially more (Currently a total of 259,466 cells for arrays). 
# 
# Feb 24 2022
#
#       Last night it kinda hit me that splitting into 15 different relationships is what needs to be done, however, not all relationships are equal in
#       value. What I mean by this is that some relationships can be more or less important than others, for example:
#       
#               $$$$$ will always be size 1 since this only applies to the guessed word
#               XXXXX doesn't get much information on the word
#
#       I don't have hard proof that relations other than $$$$$ won't be as important, however, it's important to keep this in mind moving forward.
#
#       My dumbass just realized there are more than 15 relations since I didn't account for having more than two types of outputs. Missing ones are:
#
#       XXXO$
#       XXOO$
#       XXO$$
#       XOOO$
#       XOO$$
#       XO$$$
#
#       Now I'm going insane since the first set of relations was 15 and this one is 6 yet in the program I only have 20. I counted them and compared
#       multiple times but can't find a duplicate. I think I'm crazy.
#
#       Tq taught me some dynamic memory allocation for 2d arrays and how to fix math.h now really being included. This program should be working soon.
